{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "DATE_FORMAT = \"%Y-%m-%d\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read dfs\n",
    "account   = pd.read_csv(\"dados/pre-processed/account.csv\")\n",
    "loan_dev  = pd.read_csv(\"dados/pre-processed/loan_dev.csv\")\n",
    "loan_comp = pd.read_csv(\"dados/pre-processed/loan_comp.csv\")\n",
    "loan   = pd.concat([loan_dev, loan_comp])\n",
    "loan   = loan[[\"account_id\", \"loan_date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop unecessary columns\n",
    "columns_to_drop = [\n",
    "    \"acc_creation_year\",\n",
    "    \"acc_creation_month\",\n",
    "    \"acc_creation_day\",\n",
    "]\n",
    "account.drop(columns=columns_to_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace categorical data with numerical\n",
    "account[\"frequency\"].replace(\n",
    "    [\"monthly issuance\", \"weekly issuance\", \"issuance after transaction\"],\n",
    "    range(0, 3),\n",
    "    inplace = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge with loan using account id\n",
    "df = pd.merge(account, loan, on=\"account_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ACCOUNTS WITH NO LOANS WILL HAVE TODAYS LOAN_DATE\n",
    "## THIS IS NOT AN ISSUE SINCE WE WILL ONLY TRAIN WITH ACCOUNTS THAT ASKED FOR A LOAN\n",
    "df.fillna(\"2022-11-21\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"loan_data\"]         = df[\"loan_date\"].apply(lambda x: datetime.strptime(x, DATE_FORMAT))\n",
    "df[\"acc_creation_date\"] = df[\"acc_creation_date\"].apply(lambda x: datetime.strptime(x, DATE_FORMAT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"acc_age_at_loan\"] = df.apply(lambda x: math.floor((x[\"loan_date\"] - x[\"acc_creation_date\"]).days / 30), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"loan_date\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dados/cleaned/account.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read competion and develop dataframes\n",
    "card_comp = pd.read_csv(\"dados/pre-processed/card_comp.csv\")\n",
    "card_dev = pd.read_csv(\"dados/pre-processed/card_dev.csv\")\n",
    "\n",
    "## Concat them\n",
    "card = pd.concat([card_comp, card_dev])\n",
    "\n",
    "## Drop type column of disposition\n",
    "disp_df = pd.read_csv(\"dados/pre-processed/disp.csv\")\n",
    "disp_df.drop(\"type\", axis=1, inplace=True)\n",
    "\n",
    "## Merge card with disposition (how=Left so we have all clients and not only those with cards)\n",
    "card_disp = pd.merge(disp_df, card, on=\"disp_id\", how=\"left\")\n",
    "\n",
    "## Readability\n",
    "card_disp.rename(columns = {\"type\":\"type_card\"}, inplace=True)\n",
    "\n",
    "## Replace NaN values with \"Other\"\n",
    "card_disp[\"type_card\"].fillna(\"other\", inplace=True)\n",
    "\n",
    "## Type of card from numerical to categorical\n",
    "card_disp = pd.get_dummies(card_disp, columns = ['type_card'])\n",
    "\n",
    "## Function to check whether a person has a card\n",
    "def has_card(row):\n",
    "    return 0 if pd.isna(row[\"card_id\"]) else 1\n",
    "\n",
    "## Apply function to new column\n",
    "card_disp[\"has_card\"] = card_disp.apply(lambda x: has_card(x), axis = 1)\n",
    "\n",
    "## Drop columns\n",
    "card_disp.drop([\"card_issued_date\", \"card_id\", \"account_id\", \"client_id\"], axis=1, inplace=True)\n",
    "\n",
    "## Save\n",
    "card_disp.to_csv(\"dados/cleaned/card.csv\", index=False)\n",
    "\n",
    "card_disp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>district_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id  district_id  sex  age\n",
       "0          1           18    1   29\n",
       "1          2            1    0   54\n",
       "2          3            1    1   59\n",
       "3          4            5    0   43\n",
       "4          5            5    1   39"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read useful dataframes\n",
    "client = pd.read_csv(\"dados/pre-processed/client.csv\")\n",
    "\n",
    "## Sex from categorical to numerical\n",
    "client['sex'].replace(['m', 'f'], [0, 1], inplace=True)\n",
    "\n",
    "def get_age(row):\n",
    "    collected_date = datetime.strptime(\"2000-01-01\", DATE_FORMAT)\n",
    "    date = datetime.strptime(row[\"birthdate\"], DATE_FORMAT)\n",
    "    return collected_date.year - date.year - ((collected_date.month, collected_date.day) < (date.month, date.day))\n",
    "\n",
    "client[\"age\"] = client.apply(lambda row: get_age(row), axis = 1)\n",
    "\n",
    "columns_to_drop=[\n",
    "                \"birthdate\",\n",
    "                \"birthdate_year\",\n",
    "                \"birthdate_month\",\n",
    "                \"birthdate_day\"\n",
    "                ]\n",
    "\n",
    "client.drop(columns=columns_to_drop, axis=1, inplace = True)\n",
    "## To csv\n",
    "client.to_csv(\"dados/cleaned/client.csv\", index = False)\n",
    "client.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp   = pd.read_csv(\"dados/pre-processed/disp.csv\")\n",
    "\n",
    "def is_account_shared(account_id):\n",
    "    return 1 if disp[\"account_id\"].value_counts()[account_id] > 1 else 0\n",
    "\n",
    "## Check if an account is shared\n",
    "disp[\"is_account_shared\"] = disp.apply(lambda row: is_account_shared(row[\"account_id\"]), axis = 1)\n",
    "\n",
    "## Keep only account owners\n",
    "disp = disp[disp[\"type\"] == \"owner\"]\n",
    "\n",
    "\n",
    "## Drop type column\n",
    "disp.drop(\"type\", axis=1, inplace=True)\n",
    "\n",
    "## To CSV\n",
    "disp.to_csv(\"dados/cleaned/disp.csv\", index=False)\n",
    "\n",
    "disp.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read df\n",
    "dist = pd.read_csv(\"dados/pre-processed/district.csv\")\n",
    "\n",
    "## Standardize values\n",
    "dist[\"num_crimes_95\"] = round(dist[\"num_crimes_95\"]/dist[\"num_inhab\"] * 1000, 2)\n",
    "dist[\"num_crimes_96\"] = round(dist[\"num_crimes_96\"]/dist[\"num_inhab\"] * 1000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find missing values\n",
    "dist.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We have missing values in both perc_unemploy_95 and num_crimes_95. \n",
    "## We can deal with it by using the data avaliable in other years\n",
    "dist[\"perc_unemploy_95\"].fillna(dist[\"perc_unemploy_96\"], inplace=True)\n",
    "dist[\"num_crimes_95\"].fillna(dist[\"num_crimes_96\"], inplace=True)\n",
    "\n",
    "## Deal with missing Prague zoning\n",
    "dist.loc[dist[\"region\"] == \"Prague\", [\"region_zone\"]] = \"Prague\"\n",
    "\n",
    "dist.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop some columns\n",
    "columns_to_drop = [\n",
    "    'num_municip_inhab_0_499',\n",
    "    'num_municip_inhab_500_1999', \n",
    "    'num_municip_inhab_2000_9999',\n",
    "    'num_municip_inhab_10000_', \n",
    "    'num_cities'\n",
    "    ]\n",
    "dist.drop(columns=columns_to_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist[[\"perc_unemploy_95\", \"perc_unemploy_96\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist[[\"num_crimes_95\", \"num_crimes_96\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since those variables are correlated, let's drop both and keep only the average value\n",
    "dist[\"num_crimes\"]   = round((dist[\"num_crimes_95\"] + dist[\"num_crimes_96\"]) / 2, 2)\n",
    "dist[\"unemployment\"] = round((dist[\"perc_unemploy_95\"] + dist[\"perc_unemploy_96\"]) / 2, 2)\n",
    "\n",
    "## Calculate the unemployment variation in %\n",
    "dist[\"unemployment_delta\"] = round((dist[\"perc_unemploy_96\"] - dist[\"perc_unemploy_95\"]) / dist[\"perc_unemploy_95\"] , 2)\n",
    "dist[\"crimes_delta\"]       = round((dist[\"num_crimes_96\"] - dist[\"num_crimes_95\"]) / dist[\"num_crimes_95\"] * 100, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop columns\n",
    "columns_to_drop = [\n",
    "    'perc_unemploy_95',\n",
    "    'perc_unemploy_96',\n",
    "    'num_crimes_95',\n",
    "    'num_crimes_96'\n",
    "]\n",
    "\n",
    "dist.drop(columns=columns_to_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist[\"region\"].replace([\"Prague\", \"Bohemia\", \"Moravia\"], range(0,3), inplace = True)\n",
    "dist[\"region_zone\"].replace([\"north\", \"west\", \"south\", \"east\", \"central\", \"Prague\"], range(0,6), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.to_csv(\"dados/cleaned/district.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dev = pd.read_csv(\"dados/pre-processed/loan_dev.csv\")\n",
    "loan_comp  = pd.read_csv(\"dados/pre-processed/loan_comp.csv\")\n",
    "\n",
    "## Drop some columns\n",
    "columns_to_drop = [\"loan_year\", \"loan_month\", \"loan_day\"]\n",
    "loan_dev.drop(columns=columns_to_drop, axis = 1, inplace = True)\n",
    "loan_comp.drop(columns=columns_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "loan_dev.to_csv(\"dados/cleaned/loan_dev.csv\", index = False)\n",
    "loan_comp.to_csv(\"dados/cleaned/loan_comp.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load training(dev) and testing(comp) datasets\n",
    "trans_dev = pd.read_csv(\"dados/pre-processed/trans_dev.csv\")\n",
    "trans_dev.drop([\"trans_day\", \"trans_year\", \"trans_month\"], axis = 1, inplace = True)\n",
    "loan_dev = pd.read_csv(\"dados/pre-processed/loan_dev.csv\", usecols=[\"duration\", \"amount\", \"status\", \"account_id\", \"loan_date\"])\n",
    "\n",
    "trans_comp  = pd.read_csv(\"dados/pre-processed/trans_comp.csv\")\n",
    "trans_comp.drop([\"trans_day\", \"trans_year\", \"trans_month\"], axis = 1, inplace = True)\n",
    "loan_comp = pd.read_csv(\"dados/pre-processed/loan_comp.csv\", usecols=[\"duration\", \"amount\", \"status\", \"account_id\", \"loan_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    ## Consider nan operations as others\n",
    "    df[\"operation\"].fillna(\"other\", inplace=True)\n",
    "\n",
    "    ## Consider empty symbols as other symbols\n",
    "    df[\"k_symbol\"].replace(\"\", \"other\", inplace=True)\n",
    "    df[\"k_symbol\"].replace(\" \", \"other\", inplace=True)\n",
    "\n",
    "    ## Consider nan symbols as none\n",
    "    df[\"k_symbol\"].fillna(\"none\", inplace=True)\n",
    "\n",
    "    ## Consider empty bank as other bank\n",
    "    df[\"bank\"].replace(\"\", \"other\", inplace=True)\n",
    "\n",
    "\n",
    "    ## Table that says whether a payment has a characterization\n",
    "    df[\"has_symbol\"] = df.apply(lambda x: 0 if x[\"k_symbol\"] == \"none\" else 1, axis = 1)\n",
    "\n",
    "    ## Table that says whether a payment is of type: sanction\n",
    "    df[\"is_sanction\"] = df.apply(lambda x: 1 if x[\"k_symbol\"] == \"sanction interest if negative balance\" else 0, axis = 1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_account_shared(account_id: int) -> bool:\n",
    "    return 1 if disp[\"account_id\"].value_counts()[account_id] > 1 else 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(trans, loan):\n",
    "    df = pd.merge(trans, loan, on=\"account_id\", suffixes=('_trans', '_loan'))\n",
    "    newdf = df.copy()\n",
    "\n",
    "    ############## -> Check if an account only made transactions to account with NAN values <-##############\n",
    "    df[\"account\"].fillna(0, inplace=True)\n",
    "    df[\"to_NAN\"] = df.apply(lambda x : 1 if x[\"account\"] == 0 else 0, axis = 1)\n",
    "\n",
    "    df = df.groupby(['account_id'], as_index=False).agg(\n",
    "                                only_to_na = pd.NamedAgg(column='to_NAN', aggfunc='min')\n",
    "                                )\n",
    "    \n",
    "    ############## -> Check balance min, avg and max in the N months preceding a loan request <-##############\n",
    "    ## Convert dates to comparable format\n",
    "    newdf[\"trans_date\"] = newdf[\"trans_date\"].apply(lambda x: datetime.strptime(x, DATE_FORMAT))\n",
    "    newdf[\"loan_date\"] = newdf[\"loan_date\"].apply(lambda x: datetime.strptime(x, DATE_FORMAT))\n",
    "\n",
    "    ## Drop rows with transactions after loan\n",
    "    newdf[newdf[\"loan_date\"] > newdf[\"trans_date\"]]\n",
    "\n",
    "    # -> Check the balance of an account in N months before a loan request\n",
    "    MONTHS = 12\n",
    "    newdf[\"diff_days\"]   = newdf.apply(lambda x: (x[\"loan_date\"] - x[\"trans_date\"]).days, axis = 1)\n",
    "    newdf[\"diff_months\"] = newdf.apply(lambda x: math.floor(x[\"diff_days\"] / 30), axis = 1)\n",
    "    newdf = newdf[newdf[\"diff_months\"] < MONTHS]\n",
    "\n",
    "    newdf = newdf[[\"account_id\", \"balance\", \"is_sanction\"]]\n",
    "\n",
    "    newdf = newdf.groupby(['account_id'], as_index=False).agg(\n",
    "                                min_balance = pd.NamedAgg(column='balance', aggfunc='min'),\n",
    "                                avg_balance = pd.NamedAgg(column='balance', aggfunc='mean'), \n",
    "                                max_balance = pd.NamedAgg(column='balance', aggfunc='max'),\n",
    "                                sanctions   = pd.NamedAgg(column='is_sanction', aggfunc='sum'))\n",
    "\n",
    "    return pd.merge(newdf, df, on='account_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_comp  = clean_data(trans_comp)\n",
    "trans_dev   = clean_data(trans_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_comp  = create_features(trans_comp, loan_comp)\n",
    "trans_dev   = create_features(trans_dev, loan_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_comp  = create_features(trans_comp, loan_comp)\n",
    "trans_dev   = create_features(trans_dev, loan_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_comp.to_csv(\"dados/cleaned/trans_comp.csv\", index=False)\n",
    "trans_dev.to_csv(\"dados/cleaned/trans_dev.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
